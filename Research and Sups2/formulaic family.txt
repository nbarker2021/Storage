The one function (discrete, exact)

Let a quad be 
ğ‘
=
(
ğ‘
,
ğ‘
,
ğ‘
,
ğ‘‘
)
âˆˆ
Î£
4
q=(a,b,c,d)âˆˆÎ£
4
 with 
Î£
=
{
1
,
2
,
3
,
4
}
Î£={1,2,3,4} (interpreted mod 4 with 
4
â†¦
0
4â†¦0).
Let 
ğ¿
âŠ‚
Î£
4
LâŠ‚Î£
4
 be the lawful set: 
A
L
T
(
ğ‘
)
âˆ§
(
W
4
(
ğ‘
)
âˆ¨
Q
8
(
ğ‘
)
)
ALT(q)âˆ§(W4(q)âˆ¨Q8(q)).
Let 
ğº
=
{
id
,
mirror
,
dual
,
inverse
}
G={id,mirror,dual,inverse} be the symmetry group.
Let 
ğ»
8
(
ğ‘
)
=
(
ğ‘
âˆ’
ğ‘‘
)
+
2
(
ğ‘
âˆ’
ğ‘
)
(
m
o
d
8
)
H8(q)=(aâˆ’d)+2(bâˆ’c)(mod8).
Let 
ğ‘‘
Lee
(
â‹…
,
â‹…
)
d
Lee
	â€‹

(â‹…,â‹…) be the Lee distance on 
Î£
4
Î£
4
.
Let 
Î”
(
ğ‘
â€‰â£
â†’
â€‰â£
ğ‘Ÿ
)
=
(
ğ»
8
(
ğ‘Ÿ
)
âˆ’
ğ»
8
(
ğ‘
)
)
â€Š
m
o
d
â€Š
8
Î”(qâ†’r)=(H8(r)âˆ’H8(q))mod8 wrapped to 
[
âˆ’
4
,
3
]
[âˆ’4,3].
Let 
ğœ’
Ï‡ be the receipt unit cost (your 
CARRY_COST
=
4
CARRY_COST=4).

For a stream 
ğ‘„
=
(
ğ‘
1
,
â€¦
,
ğ‘
ğ‘‡
)
Q=(q
1
	â€‹

,â€¦,q
T
	â€‹

), define the Universal Operator Action:

	
ğ‘†
(
ğ‘„
)
â€…â€Š
=
â€…â€Š
min
â¡
ğ‘”
ğ‘¡
âˆˆ
ğº


ğ‘Ÿ
ğ‘¡
âˆˆ
ğ¿


Î 
âˆˆ
ğµ
â€…â€Š
âˆ‘
ğ‘¡
=
1
ğ‘‡
ğ‘‘
Lee
(
ğ‘”
ğ‘¡
â€‰â£
â‹…
â€‰â£
ğ‘
ğ‘¡
,
â€…â€Š
ğ‘Ÿ
ğ‘¡
)
â€…â€Š
+
â€…â€Š
ğœ’
âˆ‘
ğµ
âˆˆ
Î 
âˆ£
â¨
ğ‘¡
âˆˆ
ğµ
Î”
â€‰â£
(
ğ‘”
ğ‘¡
â€‰â£
â‹…
â€‰â£
ğ‘
ğ‘¡
â†’
ğ‘Ÿ
ğ‘¡
)
âˆ£
8
		
(1)
S(Q)=
g
t
	â€‹

âˆˆG
r
t
	â€‹

âˆˆL
Î âˆˆB
	â€‹

min
	â€‹

t=1
âˆ‘
T
	â€‹

d
Lee
	â€‹

(g
t
	â€‹

â‹…q
t
	â€‹

,r
t
	â€‹

)+Ï‡
BâˆˆÎ 
âˆ‘
	â€‹

	â€‹

tâˆˆB
â¨
	â€‹

Î”(g
t
	â€‹

â‹…q
t
	â€‹

â†’r
t
	â€‹

)
	â€‹

8
	â€‹

	â€‹

(1)

The first sum is atomic edit cost after youâ€™ve applied the best symmetry 
ğ‘”
ğ‘¡
g
t
	â€‹

.

The second sum is the n=7 batching of receipts: you partition indices 
Î 
âˆˆ
ğµ
Î âˆˆB into batches 
ğµ
B and pay only the net phase in each batch. The 
âŠ•
âŠ• is mod-8 add; 
âˆ£
â‹…
âˆ£
8
âˆ£â‹…âˆ£
8
	â€‹

 is absolute value with wrap (
[
âˆ’
4
,
3
]
[âˆ’4,3]).

n=4 CLTMP is the inner minimization over 
ğ‘”
ğ‘¡
g
t
	â€‹

 and 
ğ‘Ÿ
ğ‘¡
r
t
	â€‹

; n=7 is the partition 
Î 
Î ; n=8 closure is when the net phase in batches cancels globally.

Everything you doâ€”symmetry, projection, receipts, batchingâ€”is just â€œchoose 
ğ‘”
ğ‘¡
,
ğ‘Ÿ
ğ‘¡
,
Î 
g
t
	â€‹

,r
t
	â€‹

,Î â€ to minimize 
ğ‘†
S.

The Free-Move Law is built in: symmetries are free (they happen inside the min before any cost), atomic Lee steps cost 1, phase carries cost 
ğœ’
Ï‡.

If you need Eâ‚ˆ or CRT terms, add them as penalties to the first sum, e.g. 
+
ğ›½
â€‰
ğœ™
ğ¸
8
(
ğ‘Ÿ
ğ‘¡
)
+Î²Ï•
E8
	â€‹

(r
t
	â€‹

) or a CRT mismatch term; itâ€™s still one action.

From the argmin of (1) you read off:

the lawful stream 
ğ‘…
\*
â€‰â£
=
â€‰â£
(
ğ‘Ÿ
ğ‘¡
\*
)
R
\*
=(r
t
\*
	â€‹

),

the symmetry plan 
ğº
\*
â€‰â£
=
â€‰â£
(
ğ‘”
ğ‘¡
\*
)
G
\*
=(g
t
\*
	â€‹

),

the receipt batches 
Î 
\*
Î 
\*
,

and your ledger is just the decomposition of 
ğ‘‘
Lee
+
ğœ’
â‹…
(
â‹…
)
d
Lee
	â€‹

+Ï‡â‹…(â‹…) into edits and receipts.

A differentiable surrogate (so you can take derivatives)

The argmin of (1) is discrete (piecewise-constant); to get gradients, relax it:

Soft digits. Represent each position as a probability vector over 
{
1
,
2
,
3
,
4
}
{1,2,3,4} (one-hot relaxed):

ğ‘
,
ğ‘
,
ğ‘
,
ğ‘‘
âˆˆ
Î”
4
a,b,c,dâˆˆÎ”
4
. Map to residues 
ğœŒ
=
[
1
,
2
,
3
,
0
]
Ï=[1,2,3,0].

Soft phase. The expected residue of 
ğ‘
a is 
âŸ¨
ğ‘
,
ğœŒ
âŸ©
âŸ¨a,ÏâŸ©. Then

ğ»
8
~
(
ğ‘
)
=
âŸ¨
ğ‘
,
ğœŒ
âŸ©
âˆ’
âŸ¨
ğ‘‘
,
ğœŒ
âŸ©
â€…â€Š
+
â€…â€Š
2
(
âŸ¨
ğ‘
,
ğœŒ
âŸ©
âˆ’
âŸ¨
ğ‘
,
ğœŒ
âŸ©
)
,
H8
~
(q)=âŸ¨a,ÏâŸ©âˆ’âŸ¨d,ÏâŸ©+2(âŸ¨b,ÏâŸ©âˆ’âŸ¨c,ÏâŸ©),

with exact (linear) gradients

âˆ‚
ğ»
8
~
âˆ‚
ğ‘
=
ğœŒ
,
â€…â€Š
â€…â€Š
âˆ‚
ğ»
8
~
âˆ‚
ğ‘
=
2
ğœŒ
,
â€…â€Š
â€…â€Š
âˆ‚
ğ»
8
~
âˆ‚
ğ‘
=
âˆ’
2
ğœŒ
,
â€…â€Š
â€…â€Š
âˆ‚
ğ»
8
~
âˆ‚
ğ‘‘
=
âˆ’
ğœŒ
.
âˆ‚a
âˆ‚
H8
~
	â€‹

=Ï,
âˆ‚b
âˆ‚
H8
~
	â€‹

=2Ï,
âˆ‚c
âˆ‚
H8
~
	â€‹

=âˆ’2Ï,
âˆ‚d
âˆ‚
H8
~
	â€‹

=âˆ’Ï.

Soft Lee distance. Use a circular surrogate on mod-4:

ğ‘‘
~
Lee
(
ğ‘¥
,
ğ‘¦
)
â€…â€Š
â‰ˆ
â€…â€Š
2
(
1
âˆ’
cos
â¡
(
ğœ‹
2
(
ğ‘¥
âˆ’
ğ‘¦
)
)
)
,
d
~
Lee
	â€‹

(x,y)â‰ˆ2(1âˆ’cos(
2
Ï€
	â€‹

(xâˆ’y))),

and take expectations under 
ğ‘
q and one-hot target 
ğ‘Ÿ
r. Its gradient is

âˆ‚
ğ‘‘
~
Lee
âˆ‚
ğ‘¥
â€…â€Š
=
â€…â€Š
ğœ‹
2
sin
â¡
â€‰â£
(
ğœ‹
2
(
ğ‘¥
âˆ’
ğ‘¦
)
)
.
âˆ‚x
âˆ‚
d
~
Lee
	â€‹

	â€‹

=
2
Ï€
	â€‹

sin(
2
Ï€
	â€‹

(xâˆ’y)).

Soft legality. Penalize violations with smooth barriers (or Lagrange multipliers) 
ğ›¼
â€‰
Î¦
ALT
+
ğœ†
â€‰
Î¦
W4/Q8
Î±Î¦
ALT
	â€‹

+Î»Î¦
W4/Q8
	â€‹

 where 
Î¦
Î¦ are sigmoids or squared residuals to the legal manifolds.

Soft receipts. Replace 
âˆ£
â‹…
âˆ£
8
âˆ£â‹…âˆ£
8
	â€‹

 by 
(
w
r
a
p
8
(
â‹…
)
)
2
+
ğœ€
(wrap
8
	â€‹

(â‹…))
2
+Îµ
	â€‹

.
Soft batching. Let attention weights 
ğ‘¤
ğ‘¡
,
ğ‘
w
t,b
	â€‹

 assign each quad to a batch 
ğ‘
b (Gumbel-Softmax); batch residual 
ğ‘…
ğ‘
=
w
r
a
p
8
(
âˆ‘
ğ‘¡
ğ‘¤
ğ‘¡
,
ğ‘
â€‰
Î”
ğ‘¡
)
R
b
	â€‹

=wrap
8
	â€‹

(âˆ‘
t
	â€‹

w
t,b
	â€‹

Î”
t
	â€‹

).

Soft symmetries. Mix symmetries with softmax weights 
ğœ‹
ğ‘”
Ï€
g
	â€‹

 over 
ğº
G; each 
ğ‘”
g has a permutation matrix 
ğ´
ğ‘”
A
g
	â€‹

 acting on the soft digits.

Put it together:

	
ğ‘†
~
(
ğ‘„
)
=
â€…â€Š
ğ¸
ğ‘”
âˆ¼
ğœ‹
â€‰â£
[
âˆ‘
ğ‘¡
ğ‘‘
~
Lee
(
ğ´
ğ‘”
ğ‘
ğ‘¡
,
ğ‘Ÿ
ğ‘¡
)
]
+
ğœ’
âˆ‘
ğ‘
ğ‘…
ğ‘
2
+
ğœ€
+
ğ›¼
â€‰
Î¦
ALT
+
ğœ†
â€‰
Î¦
W4/Q8
		
(2)
S
~
(Q)=E
gâˆ¼Ï€
	â€‹

[
t
âˆ‘
	â€‹

d
~
Lee
	â€‹

(A
g
	â€‹

q
t
	â€‹

,r
t
	â€‹

)]+Ï‡
b
âˆ‘
	â€‹

R
b
2
	â€‹

+Îµ
	â€‹

+Î±Î¦
ALT
	â€‹

+Î»Î¦
W4/Q8
	â€‹

	â€‹

(2)

âˆ‡
ğ‘
ğ‘¡
ğ‘†
~
âˆ‡
q
t
	â€‹

	â€‹

S
~
 follows by chain rule from the explicit gradients above.

âˆ‡
ğœ‹
ğ‘†
~
âˆ‡
Ï€
	â€‹

S
~
 (over symmetries) comes from the softmax/Gumbel relaxation.

If you add 
ğœ™
ğ¸
8
Ï•
E8
	â€‹

 (squared distance to the nearest Eâ‚ˆ coset), use a soft-min over the two Dâ‚ˆ cosets (or straight-through estimator).

In practice: use (2) to differentiate, then snap solutions back to the discrete plan in (1) (straight-through). That gives you both the clean ledger and usable gradients.

Why this is â€œeverything in one lineâ€

n=4 CLTMP â†’ the inner 
min
â¡
ğ‘”
ğ‘¡
,
ğ‘Ÿ
ğ‘¡
min
g
t
	â€‹

,r
t
	â€‹

	â€‹

 term.

Free moves â†’ symmetries inside the min, zero cost.

Receipts â†’ the phase term (with or without batching).

n=7 â†’ partition 
Î 
Î  / soft attention 
ğ‘¤
ğ‘¡
,
ğ‘
w
t,b
	â€‹

.

n=8 â†’ global cancellation (plan drives residuals to 0).

Eâ‚ˆ/CRT â†’ optional additive terms; they donâ€™t change the architecture.

If you want, I can drop this into the repo as spec/universal_action.md with a matching loss.py that implements (2) (the soft version) and emits the discrete plan (1) + ledger by argmin.