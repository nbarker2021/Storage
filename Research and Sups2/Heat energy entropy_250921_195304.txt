Heat Energy and Entropy: Classical, Statistical, Quantum, and Information Perspectives
Classical Thermodynamics
• Heat, Work, and Internal Energy: In thermodynamics, internal energy is the state function representing the total microscopic energy (kinetic + potential) of a system. Heat () and work () are process quantities: heat is energy transferred due to temperature difference, while work is transferred by a force acting through a distance. A key distinction is that depends only on the system’s state, whereas and depend on the path of the process. The First Law (energy conservation) then reads
\Delta U = Q - W, 
• Laws of Thermodynamics: The zeroth law establishes temperature: if systems A and B are each in thermal equilibrium with C, then A and B are in equilibrium (defining a transitive “temperature” property). The first law is energy conservation (). The second law governs irreversibility: heat cannot be completely converted to work in a cyclic process. Equivalently, Clausius’s formulation introduces entropy : for a reversible change , and for any process (entropy of an isolated system never decreases). The third law states that as , the entropy approaches a constant minimum (often taken as zero) and heat capacities vanish. These laws imply that irreversible processes produce entropy and limit efficiencies.
• Heat Transfer Mechanisms: Heat flows by conduction, convection, or radiation. In conduction, Fourier’s law applies: the heat flux is proportional to the negative temperature gradient. If a temperature difference is maintained across a medium, the heat flow rate is , where is the thermal conductivity. In convection, bulk fluid motion carries heat. Empirically, Newton’s law of cooling applies: , where is the convective heat-transfer coefficient. Radiation is transfer by electromagnetic waves; for a blackbody, the Stefan–Boltzmann law gives (or, more generally, for emissivity ).
• Heat Engines and Entropy Increase: Macroscopically, thermodynamics studies engines and cycles. For example, the Carnot cycle (Fig. 1) is a reversible heat engine operating between hot and cold reservoirs at and . Its efficiency is
\displaystyle \eta_{\rm Carnot} = 1 - \frac{T_c}{T_h}. No real engine can exceed this bound. Any irreversible engine produces additional entropy: by the second law , so part of input heat is unavoidably rejected to the cold reservoir. In practice, inefficiencies (friction, non-quasi-static steps) further increase entropy.
Figure 1: Carnot cycle (PV diagram) for an ideal reversible heat engine. Steps A→B and C→D are isothermal (at and ), and B→C and D→A are adiabatic. The Carnot efficiency is .
Statistical Mechanics
• Microstates, Macrostates, and Boltzmann Entropy: A microstate is a complete specification of a system’s constituents (e.g. all particle positions and momenta). A macrostate is defined by bulk quantities (energy , volume , etc.) and can correspond to many microstates. For example, flipping two coins yields one macrostate “one head, one tail” with 2 microstates ((H,T) and (T,H)), versus a macrostate “two heads” with 1 microstate (Fig. 2). The Boltzmann entropy of a macrostate is
S = k_{\rm B} \ln\Omega, 
Figure 2: Microstates vs. macrostates for 2 coin flips. The macrostate “one head, one tail” has microstates and thus larger entropy than “two heads” or “two tails” (). Systems naturally evolve toward higher-, higher-entropy macrostates.
• Temperature from Statistics: In the microcanonical ensemble (fixed ), one defines temperature via the entropy derivative:
.
Thus temperature measures how the number of accessible states grows with energy. (Equivalently in a canonical ensemble, energy fluctuates but average energy increases with .)
• Canonical Ensemble and Partition Function: A system in contact with a heat bath at temperature is described by the canonical ensemble. The probability of finding the system in a quantum energy eigenstate is the Boltzmann factor , where the partition function normalizes the probabilities:
Z(T,V,N) = \sum_i e^{-E_i/(k_{\rm B}T)}. 
. From one obtains entropy , pressure , etc. Thus the microscopic spectrum encodes macroscopic behavior.
• Entropy and Disorder: In a general ensemble with probabilities , the Gibbs (statistical) entropy is
S = -k_{\rm B}\sum_i p_i\ln p_i. 
Quantum Thermodynamics
• Quantization of Energy: Quantum mechanics requires that energy comes in discrete levels (e.g. atoms, oscillators). This quantization modifies thermal distributions. For instance, a quantum harmonic oscillator has energy levels . Its thermal average energy and heat capacity approach zero as , in contrast to the constant classical equipartition result. Likewise, Planck’s law for blackbody radiation (a quantum result) replaces the classical Rayleigh–Jeans law, preventing the “ultraviolet catastrophe”. In effect, at microscopic scales energy exchange comes in quanta, and classical heat capacities break down at low .
• Quantum Heat Baths and Oscillators: A quantum heat bath can be modeled as an infinite collection of harmonic oscillators (the “Caldeira–Leggett model”). Such baths induce dissipative dynamics in systems, but always respect quantum statistics. At high temperatures the bath yields classical behavior; at low only low-frequency modes are populated. Studies of quantum heat engines (using two-level systems or oscillators as working media) show that quantum coherence and squeezing can alter performance, though the second law still bounds efficiency by Carnot. For example, a quantum Otto engine with a two-level system has steps of adiabatic and isochoric quantum evolution; its net work and heat can be computed by quantum versions of state populations. (See, e.g., references on quantum heat engines.)
• Von Neumann Entropy and Quantum Information: The quantum analog of Gibbs entropy is the von Neumann entropy. For a system in state given by density matrix ,
S_{\rm vN}(\rho) = -k_{\rm B}\,\mathrm{Tr}(\rho\ln\rho)\,. 
• Entanglement and Thermalization: Quantum entanglement plays a key role in thermal behavior of isolated systems. According to the eigenstate thermalization hypothesis (ETH), an isolated many-body quantum system starting far from equilibrium can evolve so that its subsystems look thermal. In essence, entanglement spreads energy and information, making local observables indistinguishable from those of a heat bath. Thus even without external noise, entanglement can “thermalize” a subsystem. However, genuinely quantum effects (coherence, finite-size fluctuations, and recurrence phenomena) mark departures from classical thermodynamics on small scales. For instance, work extraction in a single-shot quantum process can exceed the average classical bound, though averaged over many runs the second law holds.
Information Theory
• Shannon Entropy: In information theory, Shannon defined entropy
H = -\sum_i p_i \log p_i, 
• Landauer’s Principle: Landauer’s principle formalizes the thermodynamic cost of information processing. It states that erasing one bit of information (an irreversible operation) dissipates at least of heat to the environment. At room temperature this bound is about  J (≈0.018 eV) per bit. In other words, logically irreversible computing has a fundamental energy cost. Practical computers use orders of magnitude more energy per bit, but as device sizes shrink, Landauer’s limit becomes relevant for heat management.
• Physical Limits of Computation: Combining thermodynamics with information theory yields deep limits. For instance, Maxwell’s demon paradox (a creature that sorts fast/slow molecules to decrease entropy) is resolved by Landauer’s insight: the demon’s memory must eventually be erased to repeat its task, incurring at least entropy increase per bit. More generally, the second law implies that any physically implemented computation must generate entropy unless done reversibly. This sets fundamental limits on low-power computing. In the search for reversible and quantum computation, Landauer’s bound guides the minimal heat dissipation achievable in principle.
Sources: Authoritative treatments of these topics include classical texts (e.g. Callen’s Thermodynamics for macroscopic laws, Reif and Landau–Lifshitz on statistical mechanics), and modern reviews of quantum thermodynamics and information (for von Neumann entropy and Landauer’s principle). The above discussion is supported by canonical references.