Prime and Coprime Numbers in Number Theory
Prime numbers are integers greater than 1 whose only positive divisors are 1 and themselves. Equivalently, a prime is not a product of smaller naturals. The Fundamental Theorem of Arithmetic asserts that every integer $>1$ is either prime or can be written uniquely (up to order) as a product of primes. By Euclid’s classic proof, there are infinitely many primes. Primes satisfy Euclid’s lemma: if a prime $p$ divides a product $ab$, then $p$ divides at least one of $a$ or $b$. This underlies unique factorization. Primes are central to number theory and applications: for example, they underpin modern cryptography due to the difficulty of factoring large composites into their prime factors.
Two integers $a,b$ are called coprime (or relatively prime) if $\gcd(a,b)=1$, i.e. they share no prime factors. Equivalently, the only positive divisor common to $a,b$ is 1. For instance, 8 and 15 are coprime (no prime divides both), whereas 6 and 9 are not (both divisible by 3). Equivalently, Bézout’s identity guarantees that $ax + by = 1$ has an integer solution $(x,y)$ exactly when $\gcd(a,b)=1$. In that case one can “divide” modulo $a$ or $b$: $b$ has a multiplicative inverse mod $a$ (and vice versa) precisely when $a,b$ are coprime. Moreover, if $\gcd(a,b)=1$, then any system of congruences has a solution by the Chinese Remainder Theorem (CRT); in fact the solution is unique modulo $ab$.
Figure: The lattice diagram illustrates that the line from $(0,0)$ to $(4,9)$ contains no other integer points. Since 4 and 9 share no common factor, $\gcd(4,9)=1$ and they are coprime.
The Euclidean algorithm efficiently computes $\gcd(a,b)$ by repeated division with remainder. For example, to find $\gcd(33,27)$ one computes $33=1\cdot27+6$, then $27=4\cdot6+3$, then $6=2\cdot3+0$, concluding $\gcd(33,27)=3$. The extended Euclidean algorithm traces these steps backward to exhibit integers $x,y$ such that $ax+by=\gcd(a,b)$. In particular if $\gcd(a,b)=1$, one finds $ax+by=1$ and hence $a$ has a modular inverse mod $b$ (namely $x$) and $b$ has an inverse mod $a$. This connects coprimality to modular arithmetic: an integer $a$ is invertible modulo $n$ exactly when $\gcd(a,n)=1$.
Euler’s totient function $\varphi(n)$ counts the positive integers up to $n$ that are coprime to $n$. For example, the integers coprime to 9 (≤9) are ${1,2,4,5,7,8}$, so $\varphi(9)=6$. In general, $\varphi(n)=|{1\le k\le n:\gcd(k,n)=1}|$. This function is multiplicative: if $\gcd(m,n)=1$, then $\varphi(mn)=\varphi(m)\varphi(n)$. A convenient formula follows from the prime factorization of $n$: if $n=p_1^{k_1}p_2^{k_2}\cdots p_r^{k_r}$ then
\varphi(n)=n\prod_{i=1}^r\Bigl(1-\frac1{p_i}\Bigr) a^{\varphi(n)}\equiv 1\pmod n, 
Fundamental Theorems
The Fundamental Theorem of Arithmetic guarantees unique prime factorization. Combined with Euclid’s lemma and Bézout’s identity, this yields many important corollaries. For example, if $\gcd(a,b)=1$ and $a\mid bc$, then $a\mid c$. More generally, the Chinese Remainder Theorem (CRT) asserts that if $m_1,\dots,m_k$ are pairwise coprime, then the system of congruences $x\equiv a_i\pmod{m_i}$ has a unique solution modulo $M=m_1\cdots m_k$. Euler’s theorem (above) and Fermat’s little theorem are other cornerstones: for prime $p$, $a^{p-1}\equiv1\pmod p$ whenever $\gcd(a,p)=1$, a special case of Euler’s result. These theorems form the algebraic backbone of number theory: they allow reduction of problems about integers to problems about primes and modular arithmetic.
Applications in Cryptography, Coding, and Computer Science
Cryptography heavily exploits primes and coprimality. The RSA algorithm, for instance, generates a public/private key pair as follows: choose two large random primes $p,q$, let $n=pq$ and compute the totient $\varphi(n)=(p-1)(q-1)$ (or Carmichael’s $\lambda(n)=\mathrm{lcm}(p-1,q-1)$). Select a public exponent $e$ with $1<e<\varphi(n)$ such that $\gcd(e,\varphi(n))=1$. Then compute the private exponent $d$ as the modular inverse of $e$ mod $\varphi(n)$ (i.e. solve $de\equiv1\pmod{\varphi(n)}$ using the extended Euclidean algorithm). Encryption is $c\equiv m^e\bmod n$ and decryption $m\equiv c^d\bmod n$, relying on Euler’s theorem. The security of RSA hinges on the presumed hardness of factoring $n$ into its prime factors. In general, cryptographic protocols use prime fields (integers mod a prime) or groups of units mod $n$; for example, Diffie–Hellman key exchange works in a large prime field, and elliptic‐curve methods use algebraic groups over prime fields. Many cryptosystems thus depend on properties of primes, coprime exponents, and modular inverses.
Coding theory and error-correction also employ number-theoretic concepts. Many codes (e.g. BCH, Reed–Solomon) are built over finite fields $\mathrm{GF}(p^m)$, which exist only when the size is a power of a prime. In particular, binary codes and cyclic codes use $\mathrm{GF}(2)$ arithmetic: parity-check codes add bits mod 2, and cyclic redundancy checks (CRC) compute polynomial remainders over the field of two elements. The CRC attaches an $n$-bit checksum equal to the remainder of dividing the message polynomial by a fixed generator polynomial; addition in $\mathrm{GF}(2)$ has no carries, making this efficient in hardware. Thus error-detecting codes leverage arithmetic modulo 2 (a prime field) to catch bit-flip errors. More generally, linear codes treat messages as elements of a vector space over $\mathrm{GF}(p)$ and rely on properties of fields (e.g. existence of inverses for all nonzero elements when the modulus is prime) to enable both detection and correction of errors.
In computer science, primes and coprimes appear in hashing and algorithms. Hash functions often use a prime modulus to distribute values uniformly (so that combining a key $k$ with a prime $p$ via $h=k\bmod p$ avoids simple patterns). Algorithms such as the Euclidean algorithm for $\gcd$ run efficiently in $O(\log n)$ time. Randomized algorithms and pseudo-random generators frequently use modular multiplication (e.g. linear congruential generators pick large prime moduli). Furthermore, data structures like hash tables sometimes choose prime-sized tables to avoid clustering. In summary, primality tests, modular inverses, and gcd computations form fundamental tools in algorithm design.
Number Base (Radix) Systems
A base-$n$ (radix-$n$) numeral system represents integers by digits $d_k d_{k-1}\dots d_0$ where each digit $d_i$ is from $0$ to $n-1$ and contributes $d_i n^i$ to the value. For example, in the decimal system (base 10) the digits are 0–9 and the number 555 means $5\cdot10^2+5\cdot10^1+5\cdot10^0$. More generally, a positional system ensures the place of a digit scales it by a power of the base. Common systems include binary (base 2, digits {0,1}), octal (base 8, digits {0–7}), decimal (base 10, digits {0–9}), and hexadecimal (base 16, digits {0–9,A–F}). Binary is ubiquitous in computers because it directly matches binary electronic states; hexadecimal and octal provide compact groupings of binary bits (each hex digit represents 4 bits, octal 3 bits).
Conversion between bases is done by repeated division or grouping. For instance, to convert the decimal number 37 to binary: divide by 2, tracking remainders: 37÷2 =18 R1, 18÷2=9 R0, 9÷2=4 R1, 4÷2=2 R0, 2÷2=1 R0, 1÷2=0 R1, reading remainders bottom-up gives $100101_2$. Inverse conversion sums $1\cdot2^5+0\cdot2^4+0\cdot2^3+1\cdot2^2+0\cdot2^1+1\cdot2^0=37$. Arithmetic in different bases follows the same rules of addition, subtraction, etc., with carries in the given base. As a table example, the decimal 10 is written 2 (binary), 12 (octal), and A (hexadecimal) because $10_{10}=1010_2=12_8=\mathrm{A}_{16}$. Positional bases can also represent fractions by digits after a radix point (for example, 0.101 in binary means $1/2+0/4+1/8=0.625$). Base systems underlie computing (all binary machine code), digital electronics, and everyday arithmetic.
Modular Arithmetic Systems
Modular arithmetic is the arithmetic of congruence classes of integers. For a positive modulus $n$, two integers $a,b$ are congruent modulo $n$ (written $a\equiv b\ (\bmod\ n)$) if $n$ divides $a-b$. Equivalently, $a\equiv b\pmod n$ means $a$ and $b$ leave the same remainder on division by $n$. In this view, integers are partitioned into $n$ residue classes ${0,1,\dots,n-1}$, each class representing all integers congruent to that representative. Arithmetic operations (addition, subtraction, multiplication) are then performed on representatives and reduced mod $n$. Because of “wrap-around” behavior, modular arithmetic is often called clock arithmetic: for example, on a clock (modulus 12) adding 5 hours to 10:00 yields 3:00 because $10+5\equiv3\pmod{12}$. More formally, the set $\mathbb Z/n\mathbb Z={0,1,\dots,n-1}$ with addition and multiplication mod $n$ forms a ring (the integers mod $n$). If $n$ is prime, this ring is in fact a field, since every nonzero element has a multiplicative inverse.
The residue class of an integer $a$ mod $n$, denoted $[a]_n$, consists of all $b$ with $b\equiv a\pmod n$. Addition and multiplication on classes are well-defined: $[a]+[b]=[a+b]$, $[a]\cdot[b]=[ab]$ (always reduced mod $n$). The additive group $\mathbb Z/n\mathbb Z$ is always cyclic of order $n$. The set of units (elements with inverses) is the multiplicative group of integers modulo $n$. Explicitly, the invertible elements are those integers coprime to $n$, and this group has order $\varphi(n)$. The group law is multiplication mod $n$. For example, for $n=12$, the units are ${1,5,7,11}$ since each is coprime to 12; $5\cdot5\equiv1\pmod{12}$ shows $5$ is its own inverse. In general, $\gcd(a,n)=1$ is necessary and sufficient for $a$ to have a modular inverse mod $n$. The extended Euclidean algorithm gives that inverse explicitly (as in RSA key generation).
The Chinese Remainder Theorem (CRT) is a cornerstone of modular systems: if $n_1,\dots,n_k$ are pairwise coprime, then the natural map
x \;\mapsto\; (x\bmod n_1,\dots,x\bmod n_k) 
Modular arithmetic is pervasive in computing and theory. In computer science, integers naturally overflow modulo $2^k$ on $k$-bit machines. Cryptography relies on modular exponentiation (e.g. RSA uses $(m^e \bmod n)$ and inverses as above). Modular arithmetic appears in algorithms (hashing often uses a prime modulus for distributions), in cryptographic hashes, and even in puzzles like calendars and clocks (days of week cycle mod 7, hours mod 12). In abstract algebra, $\mathbb Z/n\mathbb Z$ is the prototypical finite ring (and a field when $n$ is prime), illustrating ring and field theory. The group of units $(\mathbb Z/n\mathbb Z)^\times$ of order $\varphi(n)$ is a basic example in group theory.
In summary, primes and coprimes lie at the heart of number theory: primes generate all numbers by multiplication, and coprime relationships control divisibility and invertibility. Euler’s totient function and the Euclidean algorithm quantitatively and algorithmically capture coprimality. These concepts underpin fundamental results (unique factorization, Euler’s theorem) and are applied widely in cryptography (RSA key generation, hashing), coding theory (finite fields and checksums), computing (binary/arithmetic overflow) and algorithms. Similarly, understanding bases and modular arithmetic is essential for representing numbers, performing computations, and analyzing abstract algebraic structures in mathematics and computer science.
Sources: Authoritative number theory and algebra references (see e.g. Euler’s totient; Euclid’s algorithm; RSA; finite fields; CRC codes; modular arithmetic; foundational definitions). These references provide detailed proofs and broader context for the statements above.